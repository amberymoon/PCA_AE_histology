{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0da72016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerie utili\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "import joblib \n",
    "from data_augmentation import build_balanced_augmented_tensor_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff459232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x204fb1e63d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# riproducibilità\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be55798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurazione\n",
    "image_size = 224 # dimensione a cui ridimensionare ogni immagine\n",
    "batch_size = 32  # batch size per i DataLoader\n",
    "n_components = 2342 # componenti principali che spiegano l 95% della soglia\n",
    "noise_std = 0.05\n",
    "# valori diversi di noise_std provati [0.0, 0.01, 0.05, 0.1, 0.2, 0.3]\n",
    "train_ratio, val_ratio = 0.7, 0.15  # percentuali per suddividere in train/val/test\n",
    "\n",
    "pretty_labels = ['adenocarcinoma', 'beigno', 'carcinoma squamoso']  # nome delle classi più leggibili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba143910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percorsi utili\n",
    "base_dir = os.getcwd()  # percorso base\n",
    "data_dir = os.path.join(base_dir, 'data_histo') # percorso dataset\n",
    "# percorso per salvare output\n",
    "output_folder = os.path.join(base_dir, \"pca_outputs\")\n",
    "os.makedirs(output_folder, exist_ok=True) # crea se non esiste\n",
    "save_path = os.path.join(output_folder, f'pca_data_{n_components}_{noise_std}.pth')\n",
    "pca_model_path = os.path.join(output_folder, f'pca_model_{n_components}_{noise_std}.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5e87b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trasformazioni base (usate per val/test)\n",
    "transform_base = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)), # ridimensiona le immagini\n",
    "    transforms.ToTensor() # converte in tensore\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be9a1176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caricamento e split\n",
    "full_dataset = datasets.ImageFolder(root=data_dir, transform=transform_base)  # carica tutte le immagini con le etichette\n",
    "total_size = len(full_dataset)                                           # numero totale di immagini\n",
    "train_size = int(train_ratio * total_size)\n",
    "val_size = int(val_ratio * total_size)\n",
    "test_size = total_size - train_size - val_size                           # il resto va al test set\n",
    "\n",
    "# suddivisione casuale ma riproducibile\n",
    "train_indices, val_indices, test_indices = random_split(\n",
    "    list(range(total_size)), [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6cfbcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = Subset(full_dataset, train_indices)\n",
    "val_subset = Subset(full_dataset, val_indices)\n",
    "test_subset = Subset(full_dataset, test_indices)\n",
    "\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57906474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giken\\AppData\\Local\\Temp\\ipykernel_2312\\2319598802.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  aug_data = torch.load(os.path.join(\"shared_augmented_data\", f\"augmented_train_data_{noise_std}.pt\"))\n"
     ]
    }
   ],
   "source": [
    "# caricamento dati augmentati (vedi file augmented_data.ipynb)\n",
    "aug_data = torch.load(os.path.join(\"shared_augmented_data\", f\"augmented_train_data_{noise_std}.pt\"))\n",
    "train_imgs = aug_data['images']\n",
    "train_labels = aug_data['labels']\n",
    "\n",
    "# flatten immagini in vettori 1D\n",
    "train_data = train_imgs.view(train_imgs.size(0), -1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a36515a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estrazione dati: 100%|██████████| 71/71 [00:26<00:00,  2.63it/s]\n",
      "Estrazione dati: 100%|██████████| 71/71 [00:24<00:00,  2.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# estrazione e flattening di val e test\n",
    "def extract_data(loader):\n",
    "    data, labels = [], []\n",
    "    for images, targets in tqdm(loader, desc=\"Estrazione dati\"):\n",
    "        flat = images.view(images.size(0), -1)\n",
    "        data.append(flat)\n",
    "        labels.append(targets)\n",
    "    data = torch.cat(data, dim=0).numpy()\n",
    "    labels = torch.cat(labels).numpy()\n",
    "    return data, labels\n",
    "\n",
    "val_data, val_labels = extract_data(val_loader)\n",
    "test_data, test_labels = extract_data(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3931f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizzazione (Z-SCORE)\n",
    "# la normalizzazione viene effettuata utilizzando la media e la deviazione standard \n",
    "# calcolate solo sul set di training. Questo è fondamentale per evitare data leakage: \n",
    "# usare informazioni statistiche dai dati di validazione o test potrebbe introdurre bias\n",
    "# e compromettere la validità della valutazione del modello.\n",
    "mean = train_data.mean(axis=0)\n",
    "std = train_data.std(axis=0) + 1e-8  # evita divisione per zero\n",
    "\n",
    "def zscore(data):\n",
    "    return (data - mean) / std\n",
    "\n",
    "train_data = zscore(train_data)\n",
    "val_data = zscore(val_data)\n",
    "test_data = zscore(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "215856ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA(n_components=n_components)\n",
    "train_pca = pca.fit_transform(train_data) # fit su train\n",
    "val_pca = pca.transform(val_data)          # transform su val\n",
    "test_pca = pca.transform(test_data)        # transform su test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4370ab1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati PCA salvati in: c:\\Users\\giken\\Documents\\Noemi\\PCA_AE_histology\\pca_outputs\\pca_data_2342_0.05.pth\n",
      "Modello PCA salvato in: c:\\Users\\giken\\Documents\\Noemi\\PCA_AE_histology\\pca_outputs\\pca_model_2342_0.05.pkl\n"
     ]
    }
   ],
   "source": [
    "# salvataggio\n",
    "torch.save({\n",
    "    'train_data': train_pca,\n",
    "    'val_data': val_pca,\n",
    "    'test_data': test_pca,\n",
    "    'train_labels': train_labels,\n",
    "    'val_labels': val_labels,\n",
    "    'test_labels': test_labels,\n",
    "    'class_names': pretty_labels\n",
    "}, save_path)\n",
    "\n",
    "# salvataggio PCA model (per ricostruzione immagini eventualmente)\n",
    "joblib.dump(pca, pca_model_path)  # <--- NEW\n",
    "print(f\"Dati PCA salvati in: {save_path}\")\n",
    "print(f\"Modello PCA salvato in: {pca_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
