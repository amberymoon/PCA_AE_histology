{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ce090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerie\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset\n",
    "from data_augmentation import augment_data\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from torch.utils.data import random_split\n",
    "import PIL\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2b9a446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a649949fb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# riproducibilità\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55edef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurazione\n",
    "image_size = 224 # dimensione a cui ridimensionare le immagini\n",
    "noise_std = 0.2 # livello di rumore gaussiano da aggiungere ai dati augmentati\n",
    "train_ratio, val_ratio = 0.7, 0.15  # percentuali per suddividere in train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e869f944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prendo percorso base tramite os\n",
    "base_dir = os.getcwd()\n",
    "# percorso dataset  \n",
    "data_dir = os.path.join(base_dir, 'data_histo') \n",
    "# percorso per salvare output\n",
    "output_folder = os.path.join(base_dir, \"shared_augmented_data\")\n",
    "# crea se non esiste\n",
    "os.makedirs(output_folder, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa74a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trasformazioni \n",
    "transform_base = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),  # ridimensiona le immagini\n",
    "    transforms.ToTensor(),                        # converte in tensore\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54925d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caricamento dataset e applicazione trasformazioni\n",
    "full_dataset = datasets.ImageFolder(root=data_dir, transform=transform_base) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56eb564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiamo le dimensioni di train/val/test, train 70%, val 15% e test 15%\n",
    "total_size = len(full_dataset)                                           # numero totale di immagini\n",
    "train_size = int(train_ratio * total_size)\n",
    "val_size = int(val_ratio * total_size)\n",
    "test_size = total_size - train_size - val_size                           # per evitare arrotondamenti\n",
    "\n",
    "# suddivisione indici casuale per il train set ma riproducibile, \n",
    "# ci serve solo il train perchè applichiamo data augmentation solo su questo\n",
    "train_indices, _, _ = random_split(\n",
    "    list(range(total_size)), [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# recupero dei path (e delle classi) delle sole immagini di train\n",
    "train_samples = [full_dataset.samples[i] for i in train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43cd726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generazione dati augmentati...\n"
     ]
    }
   ],
   "source": [
    "# applicazione data augmentation, funzione in data_augemntation.py\n",
    "print(\"Generazione dati augmentati...\")\n",
    "train_imgs, train_labels, _ = augment_data(\n",
    "    samples=train_samples,\n",
    "    class_names=full_dataset.classes,\n",
    "    image_size=image_size,\n",
    "    mode=\"balance\",             # bilanciamento classi con oversampling\n",
    "    add_noise=True,             # aggiunta di rumore gaussiano alle immagini\n",
    "    noise_std=noise_std         # deviazione standard del rumore\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80357360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvataggio dati augmentati (immagini + etichette) per utilizzo futuro\n",
    "save_path = os.path.join(output_folder, f\"augmented_train_data_{noise_std}.pt\")\n",
    "torch.save({\n",
    "    'images': train_imgs,\n",
    "    'labels': train_labels\n",
    "}, save_path)\n",
    "\n",
    "print(f\"Dati augmentati salvati in: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd06584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvata immagine random in: c:\\Users\\noemi\\Documents\\GitHub\\PCA_AE_histology\\shared_augmented_data\\augmented_images_sample_0.2.png\n"
     ]
    }
   ],
   "source": [
    "# caricamento immagini augmentate salvate per poterne plottare qualche esempio da visualizzare\n",
    "data = torch.load(save_path, map_location=\"cpu\") \n",
    "\n",
    "images = data['images']\n",
    "labels = data['labels']\n",
    "\n",
    "# path dove salvare il plot con gli esempi\n",
    "image_path = os.path.join(output_folder, f\"augmented_images_sample_{noise_std}.png\")\n",
    "# nomi classi leggibili\n",
    "pretty_classes = ['Adenocarcinoma', 'Benigno', 'Squamoso']\n",
    "\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", size=20) # font per label\n",
    "except:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "# 3 immagini random\n",
    "indices = random.sample(range(len(images)), 3)\n",
    "imgs = []\n",
    "\n",
    "for i in indices:\n",
    "    img = images[i].detach().cpu().permute(1, 2, 0).numpy() # cambio formato con la permuta per matplot, da [C, H, W] \n",
    "                                                                # (formato tensori Pytorch) a [H, W, C] (formato compatibile con matplot) \n",
    "                                                            \n",
    "    img = np.clip(img * 255, 0, 255).astype(np.uint8)           # no, de-normalizzazione perchè in con data_augmentation non normalizziamo\n",
    "                                                                # solo conversione nel formato corretto per visualizzare l'immagine\n",
    "    img_pil = Image.fromarray(img)                              # immagini PIL\n",
    "\n",
    "    # canvas con spazio per testo\n",
    "    width, height = img_pil.size\n",
    "    canvas = Image.new(\"RGB\", (width, height + 30), color=(255, 255, 255)) # camvas con 30 pixel in più in altezza per label\n",
    "    canvas.paste(img_pil, (0, 0)) # inserisce immagine su canvas\n",
    "\n",
    "    draw = ImageDraw.Draw(canvas)\n",
    "    label = labels[i].item() # estrazione etichetta \n",
    "    class_name = pretty_classes[label] # leggibile\n",
    "\n",
    "    bbox = draw.textbbox((0, 0), class_name, font=font) # centratura testo\n",
    "    text_width = bbox[2] - bbox[0]\n",
    "    text_x = (width - text_width) // 2\n",
    "    draw.text((text_x, height + 5), class_name, fill=(0, 0, 0), font=font) # scrittura nome classe con colore testo nero (fill = (0,0,0))\n",
    "\n",
    "    imgs.append(canvas)\n",
    "\n",
    "# in una sola immagine\n",
    "combined = Image.new(\"RGB\", (width * 3, height + 30)) # griglia orizzontale per 3 immagini\n",
    "for i, img in enumerate(imgs):\n",
    "    combined.paste(img, (i * width, 0))\n",
    "\n",
    "combined.save(image_path) # salvataggio\n",
    "print(f\"Salvata immagine random in: {image_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
